{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualization on Vote Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.read.processing import Processing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "dataclass = Processing(source_path='input/datasets/')\n",
    "df = dataclass.read('vote')\n",
    "\n",
    "# Fix problem with K column name\n",
    "df.columns = ['RI', 'Na', 'Mg', 'Al', 'Si', 'K', 'Ca', 'Ba', 'Fe', 'Type']\n",
    "\n",
    "# Set class names from \"Type\" column\n",
    "d_class = {'build_wind_float':'float', 'vehic_wind_float':'float',\n",
    "           'build_wind_non-float':'non_float', 'containers':'non_wind', \n",
    "           'tableware':'non_wind', 'headlamps':'non_wind'}\n",
    "\n",
    "df['Class'] = df['Type'].map(d_class)\n",
    "df = df[df['Class'].isin(['float', 'non_float'])]\n",
    "d_class_num = {\"non_float\":0, \"float\":1}\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.decomposition.PCA import PCA\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "X_transformed = pca.fit_transform(df.iloc[:, :-2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_transformed[:, 0], X_transformed[:, 1], c=df['Class'].map(d_class_num))\n",
    "plt.title(\"PCA on Glass dataset (our implementation)\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Same with sklearn PCA\n",
    "from sklearn.decomposition import PCA as sklearnPCA\n",
    "\n",
    "sklearn_pca = sklearnPCA(n_components=2)\n",
    "X_transformed = sklearn_pca.fit_transform(df.iloc[:, :-2])\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_transformed[:, 0], X_transformed[:, 1], c=df['Class'].map(d_class_num))\n",
    "plt.title(\"PCA with sklearn\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import IncrementalPCA\n",
    "\n",
    "ipca = IncrementalPCA(n_components=2)\n",
    "X_transformed = ipca.fit_transform(df.iloc[:, :-2])\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X_transformed[:, 0], X_transformed[:, 1], c=df['Class'].map(d_class_num))\n",
    "plt.title(\"PCA with IncrementalPCA\")\n",
    "plt.xlabel(\"PC1\")\n",
    "plt.ylabel(\"PC2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import Birch, KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import silhouette_score, v_measure_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df['Type'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-2]\n",
    "y = df['Class'].map(d_class_num).values.reshape(-1, 1)\n",
    "\n",
    "n_clusters = len(np.unique(y))\n",
    "\n",
    "birch = model_dbs = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', Birch())\n",
    "])\n",
    "\n",
    "kmeans = model_dbs = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('model', KMeans(n_clusters=n_clusters))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    model.fit(X)\n",
    "    y_pred = model['model'].labels_.reshape(-1, 1)\n",
    "\n",
    "    print(f\"Silhouette score: {silhouette_score(X, y_pred)}\")\n",
    "    print(f\"V-measure score: {v_measure_score(y.squeeze(), y_pred.squeeze())}\")\n",
    "    # print(f\"Confusion matrix: \\n{confusion_matrix(y, y_pred)}\")\n",
    "    # print(f\"Classification report: \\n{classification_report(y, y_pred)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster the transformed Data using BIRCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation results on BIRCH using the original dataset\")\n",
    "evaluate_model(birch, X, y)\n",
    "\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Evaluation results on KMeans using the transformed dataset\")\n",
    "evaluate_model(birch, X_transformed, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster the transformed Data using K-Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation results on BIRCH using the original dataset\")\n",
    "evaluate_model(kmeans, X, y)\n",
    "\n",
    "print(\"-\"*50)\n",
    "\n",
    "print(\"Evaluation results on KMeans using the transformed dataset\")\n",
    "evaluate_model(kmeans, X_transformed, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "\n",
    "svd = TruncatedSVD(n_components=2)\n",
    "\n",
    "X_transformed_svd = svd.fit_transform(df.iloc[:, :-2])\n",
    "y = df['Class'].map(d_class_num).values.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster de transformed Data from the TruncatedSVD using BIRCH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation results on BIRCH using the original dataset\")\n",
    "evaluate_model(birch, X_transformed_svd, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Evaluation results on BIRCH using the original dataset\")\n",
    "evaluate_model(kmeans, X_transformed_svd, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the original Dataset\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X.to_numpy()[:, 0], X.to_numpy()[:, 1], c=df['Class'].map(d_class_num))\n",
    "plt.title(\"First 2 dimensions from Original Dataset\")\n",
    "plt.xlabel(\"X1\")\n",
    "plt.ylabel(\"X2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "birch.fit(X)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Visualize the results of BIRCH and KMenas on the original Dataset\n",
    "figure, axs = plt.subplots(1, 2, figsize=(15, 6))\n",
    "axs[0].scatter(X.to_numpy()[:, 0], X.to_numpy()[:, 1], c=birch['model'].labels_)\n",
    "axs[0].set_title(\"BIRCH results on the original Dataset\")\n",
    "axs[0].set_xlabel(\"X1\")\n",
    "axs[0].set_ylabel(\"X2\")\n",
    "\n",
    "axs[1].scatter(X.to_numpy()[:, 0], X.to_numpy()[:, 1], c=kmeans['model'].labels_)\n",
    "axs[1].set_title(\"KMeans results on the original Dataset\")\n",
    "axs[1].set_xlabel(\"X1\")\n",
    "axs[1].set_ylabel(\"X2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import Isomap\n",
    "\n",
    "isomap = Isomap(n_components=2)\n",
    "\n",
    "X_transformed = pca.fit_transform(X)\n",
    "X_transformed_isomap = isomap.fit_transform(X)\n",
    "\n",
    "# Visualize results of BIRCH and KMeans on the original Dataset using PCA and ISOMAP\n",
    "figure, axs = plt.subplots(2, 2, figsize=(15, 12))\n",
    "axs[0, 0].scatter(X_transformed[:, 0], X_transformed[:, 1], c=birch['model'].labels_)\n",
    "axs[0, 0].set_title(\"BIRCH on the original Dataset using PCA\")\n",
    "axs[0, 0].set_xlabel(\"PC1\")\n",
    "axs[0, 0].set_ylabel(\"PC2\")\n",
    "\n",
    "axs[0, 1].scatter(X_transformed[:, 0], X_transformed[:, 1], c=kmeans['model'].labels_)\n",
    "axs[0, 1].set_title(\"KMeans on the original Dataset using PCA\")\n",
    "axs[0, 1].set_xlabel(\"PC1\")\n",
    "axs[0, 1].set_ylabel(\"PC2\")\n",
    "\n",
    "axs[1, 0].scatter(X_transformed_isomap[:, 0], X_transformed_isomap[:, 1], c=birch['model'].labels_)\n",
    "axs[1, 0].set_title(\"BIRCH on the original Dataset using ISOMAP\")\n",
    "axs[1, 0].set_xlabel(\"PC1\")\n",
    "axs[1, 0].set_ylabel(\"PC2\")\n",
    "\n",
    "axs[1, 1].scatter(X_transformed_isomap[:, 0], X_transformed_isomap[:, 1], c=kmeans['model'].labels_)\n",
    "axs[1, 1].set_title(\"KMeans on the original Dataset using ISOMAP\")\n",
    "axs[1, 1].set_xlabel(\"PC1\")\n",
    "axs[1, 1].set_ylabel(\"PC2\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
