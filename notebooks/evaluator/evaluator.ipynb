{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.read.processing import Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Columns ['K'] are not in the dataset\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RI</th>\n",
       "      <th>Na</th>\n",
       "      <th>Mg</th>\n",
       "      <th>Al</th>\n",
       "      <th>Si</th>\n",
       "      <th>Ca</th>\n",
       "      <th>Ba</th>\n",
       "      <th>Fe</th>\n",
       "      <th>Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.143715</td>\n",
       "      <td>-0.758384</td>\n",
       "      <td>0.566677</td>\n",
       "      <td>-0.652289</td>\n",
       "      <td>0.490551</td>\n",
       "      <td>-0.131680</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.638803</td>\n",
       "      <td>-1.531681</td>\n",
       "      <td>0.580575</td>\n",
       "      <td>-0.190536</td>\n",
       "      <td>0.309376</td>\n",
       "      <td>-0.300715</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.143715</td>\n",
       "      <td>-0.242853</td>\n",
       "      <td>0.552779</td>\n",
       "      <td>-0.070079</td>\n",
       "      <td>-0.014151</td>\n",
       "      <td>-0.371146</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.774207</td>\n",
       "      <td>1.217820</td>\n",
       "      <td>-0.656366</td>\n",
       "      <td>0.190912</td>\n",
       "      <td>2.457593</td>\n",
       "      <td>-0.962769</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>-0.586451</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.137232</td>\n",
       "      <td>-1.359837</td>\n",
       "      <td>-1.865511</td>\n",
       "      <td>-0.893204</td>\n",
       "      <td>-3.223534</td>\n",
       "      <td>5.094318</td>\n",
       "      <td>-0.352877</td>\n",
       "      <td>1.882411</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         RI        Na        Mg        Al        Si        Ca        Ba  \\\n",
       "0 -0.143715 -0.758384  0.566677 -0.652289  0.490551 -0.131680 -0.352877   \n",
       "1 -0.638803 -1.531681  0.580575 -0.190536  0.309376 -0.300715 -0.352877   \n",
       "2 -0.143715 -0.242853  0.552779 -0.070079 -0.014151 -0.371146 -0.352877   \n",
       "3 -1.774207  1.217820 -0.656366  0.190912  2.457593 -0.962769 -0.352877   \n",
       "4  5.137232 -1.359837 -1.865511 -0.893204 -3.223534  5.094318 -0.352877   \n",
       "\n",
       "         Fe  Type  \n",
       "0 -0.586451     0  \n",
       "1 -0.586451     1  \n",
       "2 -0.586451     0  \n",
       "3 -0.586451     2  \n",
       "4  1.882411     3  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_loader = Processing()\n",
    "data_loader.read(\"glass\")\n",
    "data_loader.general_preprocessing()\n",
    "df = data_loader.df\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config\n",
    "from itertools import product\n",
    "import pandas as pd\n",
    "\n",
    "class Evaluator:\n",
    "\n",
    "    def __init__(self, \n",
    "                 model, \n",
    "                 data_loader, \n",
    "                 target: str, \n",
    "                 d_metrics: dict=config.D_METRICS,\n",
    "                 d_hyperparams: dict=config.D_HYPERPARAMS):\n",
    "        '''\n",
    "        Input:\n",
    "            model: class of the model to be evaluated \n",
    "                    (not instantiated, e.g. KMeans not KMeans())\n",
    "            data_loader: instance of the class Processing\n",
    "            target: name of the target column\n",
    "            d_metrics: dictionary with the metrics to be used\n",
    "            d_hyperparams: dictionary with the hyperparameters to be used\n",
    "\n",
    "        Attributes:\n",
    "            model, target, d_metrics, d_hyperparams\n",
    "            \n",
    "            data: dataframe with the data from data_loader\n",
    "            y_true: true labels (target column from data)\n",
    "        '''\n",
    "        self.model = model\n",
    "        self.data = data_loader.df\n",
    "        self.target = target\n",
    "        self.y_true = self.data[self.target]\n",
    "        self.d_metrics = d_metrics\n",
    "        self.d_hyperparams = d_hyperparams\n",
    "        self.df_results = None\n",
    "\n",
    "    def get_best_hyperparams(self, metric: str):\n",
    "        '''\n",
    "        Input:\n",
    "            metric: name of the metric to be used\n",
    "        Output:\n",
    "            d_best: dictionary with the best hyperparameters\n",
    "        '''\n",
    "        # Get the best hyperparameters\n",
    "        model_name = self.model.__name__\n",
    "        hyperparams = self.d_hyperparams[model_name]\n",
    "\n",
    "        d_best = self.get_top_k_hyperparams(metric, 1).to_dict('records')[0]\n",
    "\n",
    "        d_best = {k:v for k,v in d_best.items() for k in hyperparams.keys()}\n",
    "\n",
    "        return d_best\n",
    "    \n",
    "    def get_top_k_hyperparams(self, metric: str, k: int):\n",
    "        '''\n",
    "        Input:\n",
    "            metric: name of the metric to be used\n",
    "            k: number of hyperparameters to be returned\n",
    "\n",
    "        Output:\n",
    "            d_best: dictionary with the top k best hyperparameters\n",
    "        '''\n",
    "        # Get the results for each combination of hyperparameters\n",
    "        if self.df_results is None:\n",
    "            df_results = self.get_results_hyperparams()\n",
    "        else:\n",
    "            df_results = self.df_results\n",
    "\n",
    "        # Get the best hyperparameters\n",
    "        df_top_k = df_results.sort_values(by=metric, ascending=False).iloc[:k]\n",
    "\n",
    "        return df_top_k\n",
    "        \n",
    "\n",
    "\n",
    "    def get_results_hyperparams(self):\n",
    "        '''\n",
    "        Returns a dataframe with the results of the evaluation\n",
    "        for each combination of hyperparameters\n",
    "        '''\n",
    "        # Get the grid of hyperparameters\n",
    "        model_name = self.model.__name__\n",
    "        ls_hyps = self.grid_from_dict(self.d_hyperparams[model_name])\n",
    "\n",
    "        # Get the scores for each combination of hyperparameters\n",
    "        ls_scores = []\n",
    "        for hyps in ls_hyps:\n",
    "            d_scores = self.score_hyperparams(**hyps)\n",
    "            ls_scores.append(d_scores)\n",
    "\n",
    "        # Create a dataframe with the results\n",
    "        df_results = pd.DataFrame(ls_scores)\n",
    "\n",
    "        self.df_results = df_results\n",
    "        return df_results\n",
    "\n",
    "\n",
    "    def score_hyperparams(self, **kw_hyperparams):\n",
    "        '''\n",
    "        Input:\n",
    "            d_hyperparams: dictionary with the hyperparameters to be used\n",
    "        Output:\n",
    "            d_scores: dictionary with the scores for each metric\n",
    "        '''\n",
    "\n",
    "        # Get feature matrix X\n",
    "        X = self.data.drop(self.target, axis=1).copy()\n",
    "        \n",
    "        # Instantiate and fit the model with the hyperparameters\n",
    "        model = self.model(**kw_hyperparams)\n",
    "        model.fit(X)\n",
    "\n",
    "        # Get the predicted labels\n",
    "        y_pred = model.labels_\n",
    "\n",
    "        # Get the scores iterating over the internal and external scorers\n",
    "        internal_scorers = self.d_metrics[\"internal\"]\n",
    "        external_scorers = self.d_metrics[\"external\"]\n",
    "\n",
    "        d_scores = kw_hyperparams.copy()\n",
    "        d_scores['n_out_clusters'] = len(set(y_pred))\n",
    "        d_scores['n_in_classes'] = len(set(self.y_true))\n",
    "        \n",
    "        for scorer in external_scorers:\n",
    "            try:\n",
    "                score = scorer(self.y_true, y_pred)\n",
    "                d_scores[scorer.__name__] = score\n",
    "            except:\n",
    "                d_scores[scorer.__name__] = None\n",
    "        \n",
    "        for scorer in internal_scorers:\n",
    "            try:\n",
    "                score = scorer(X, y_pred)\n",
    "                d_scores[scorer.__name__] = score\n",
    "            except:\n",
    "                d_scores[scorer.__name__] = None\n",
    "        \n",
    "        return d_scores\n",
    "\n",
    "    @staticmethod\n",
    "    def grid_from_dict(d_in):\n",
    "        '''\n",
    "        Receives a dictionary of lists of hyperparameters and \n",
    "        returns a list of dictionaries with all the possible combinations\n",
    "        '''\n",
    "        # Create a list of all possible hyperparameter combinations\n",
    "        combinations = list(product(*d_in.values()))\n",
    "\n",
    "        # Print the grid of hyperparameter combinations\n",
    "        ls_hyps = []\n",
    "        for combo in combinations:\n",
    "            hyperparameters = dict(zip(d_in.keys(), combo))\n",
    "            ls_hyps.append(hyperparameters)\n",
    "            \n",
    "        return ls_hyps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'eps': 0.1854298518460819, 'min_samples': 0.1854298518460819}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.clustering.DBSCAN import DBSCAN\n",
    "model = DBSCAN\n",
    "evaluator = Evaluator(model, data_loader, target=\"Type\")\n",
    "evaluator.score_hyperparams(eps=0.5, min_samples=5)\n",
    "evaluator.get_results_hyperparams()\n",
    "evaluator.get_top_k_hyperparams(\"silhouette_score\", 2)\n",
    "evaluator.get_best_hyperparams(\"silhouette_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>eps</th>\n",
       "      <th>min_samples</th>\n",
       "      <th>n_out_clusters</th>\n",
       "      <th>n_in_classes</th>\n",
       "      <th>homogeneity_score</th>\n",
       "      <th>completeness_score</th>\n",
       "      <th>v_measure_score</th>\n",
       "      <th>silhouette_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>0.236938</td>\n",
       "      <td>0.340770</td>\n",
       "      <td>0.279523</td>\n",
       "      <td>0.185430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.9</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.204923</td>\n",
       "      <td>0.324901</td>\n",
       "      <td>0.251327</td>\n",
       "      <td>0.169437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0.204923</td>\n",
       "      <td>0.324901</td>\n",
       "      <td>0.251327</td>\n",
       "      <td>0.169437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.168327</td>\n",
       "      <td>0.307984</td>\n",
       "      <td>0.217681</td>\n",
       "      <td>0.168011</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.8</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>0.230076</td>\n",
       "      <td>0.323693</td>\n",
       "      <td>0.268972</td>\n",
       "      <td>0.161685</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    eps  min_samples  n_out_clusters  n_in_classes  homogeneity_score  \\\n",
       "67  0.9            5               5             6           0.236938   \n",
       "69  0.9            7               4             6           0.204923   \n",
       "68  0.9            6               4             6           0.204923   \n",
       "70  0.9            8               3             6           0.168327   \n",
       "58  0.8            4               6             6           0.230076   \n",
       "\n",
       "    completeness_score  v_measure_score  silhouette_score  \n",
       "67            0.340770         0.279523          0.185430  \n",
       "69            0.324901         0.251327          0.169437  \n",
       "68            0.324901         0.251327          0.169437  \n",
       "70            0.307984         0.217681          0.168011  \n",
       "58            0.323693         0.268972          0.161685  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluator.get_top_k_hyperparams(\"silhouette_score\", 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
